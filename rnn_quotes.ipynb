{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MUgSMijpDsRj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI98DxBLn4P9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZyKygnXn4P-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PkiSap1E0-p",
        "outputId": "a48e76e3-7f54-4a3a-db20-1d643175a19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of text: 1071892 characters\n"
          ]
        }
      ],
      "source": [
        "text = open('quote-text.txt', 'r').read()\n",
        "print(f'length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKoGgQN6J2iI",
        "outputId": "8b9c44eb-45fb-4ce0-9db4-5d585d1b91c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\n",
            "\n",
            "You've gotta dance like there's nobody watch\n"
          ]
        }
      ],
      "source": [
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ9RkvrSIg5r",
        "outputId": "07c1df21-2d57-45d0-8da1-073e85095ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75 unique characters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b61WVuVFLU76",
        "outputId": "f3506809-c0b8-41dc-a37d-ee82211bbb87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Before training, you need to convert the strings to a numerical representation.\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding = 'UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmqi1xBbMZpi",
        "outputId": "318de2cb-d8c6-41d1-edcf-938fb4f91240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[50, 51, 52, 53, 54, 55, 56], [73, 74, 75]]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary = list(vocab), mask_token = None)\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYbmM67MzmD",
        "outputId": "109489a2-4420-4f42-d6c7-a8eebe0d1abf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI0JFqyeXA5M",
        "outputId": "9fb9e577-6485-4606-c944-2d215ad30a7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars,axis = -1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7rYRbOBXZJJ2"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFX55N3cT7EJ",
        "outputId": "7f7ed733-4229-478d-aa89-4730670ed9da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVRiwA_oTZTD",
        "outputId": "6dd2e2f1-db7a-4632-c735-bbbcf1626161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "I\n",
            "'\n",
            "m\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFQD2baaJBD",
        "outputId": "b9bac68a-b6d1-4554-ea91-9ce91c00942d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\n' b'\\n' b'I' b\"'\" b'm' b' ' b's' b'e' b'l' b'f' b'i' b's' b'h' b','\n",
            " b' ' b'i' b'm' b'p' b'a' b't' b'i' b'e' b'n' b't' b' ' b'a' b'n' b'd'\n",
            " b' ' b'a' b' ' b'l' b'i' b't' b't' b'l' b'e' b' ' b'i' b'n' b's' b'e'\n",
            " b'c' b'u' b'r' b'e' b'.' b' ' b'I' b' ' b'm' b'a' b'k' b'e' b' ' b'm'\n",
            " b'i' b's' b't' b'a' b'k' b'e' b's' b',' b' ' b'I' b' ' b'a' b'm' b' '\n",
            " b'o' b'u' b't' b' ' b'o' b'f' b' ' b'c' b'o' b'n' b't' b'r' b'o' b'l'\n",
            " b' ' b'a' b'n' b'd' b' ' b'a' b't' b' ' b't' b'i' b'm' b'e' b's' b' '\n",
            " b'h' b'a' b'r'], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder = True)\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ETrGCTucmiD7"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEAeWsKzn-Og",
        "outputId": "f6ab429f-a882-48ab-8898-c35f9c1f0fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['t', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "split_input_target(list('tensorflow'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9McbdhooIfq",
        "outputId": "6a64db53-218f-44a7-9de2-8bd4cb8be0ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7AMxfQXotUd",
        "outputId": "6ae1d201-9f88-4401-bf6b-c2f5a2a94535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b\"\\n\\nI'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times ha\"\n",
            "Target: b\"\\nI'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times har\"\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkOIG6-V7m53",
        "outputId": "53699b99-b1ea-451f-aeee-c5b14529cf04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences, \n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
        "# it maintains a buffer in which it shuffles elements)\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_xgxHrtS-gsq"
      },
      "outputs": [],
      "source": [
        "#Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "#The embedding dimension\n",
        "embedding_dim = 256\n",
        "#Number of RNN Units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "reNmEh-I_Hc_"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "model = MyModel (\n",
        "        #be sure the vocabulary size matches the 'StringLookup' layers.\n",
        "        vocab_size = len(ids_from_chars.get_vocabulary()), embedding_dim = embedding_dim, rnn_units = rnn_units\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFwQjN9oF6d3",
        "outputId": "1ef95710-bf29-458d-98f7-db0c44565e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 76) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fyJvbXHMVb",
        "outputId": "249dedfb-27fa-4abf-fd5e-baf10e593b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  19456     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  77900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,035,660\n",
            "Trainable params: 4,035,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKwwSTtRHQWs",
        "outputId": "53e5c505-51fd-4a5f-ae56-03b96443210f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([71,  6, 69, 37, 14, 59, 45, 42, 28, 17, 31, 40, 11,  6, 15, 10, 32,\n",
              "       29,  1,  7, 52, 53, 67, 55, 32, 46, 68, 22,  4, 60, 58, 35, 41, 60,\n",
              "       67, 14, 69,  5,  3, 60, 56, 27, 49,  2,  8,  0, 70,  5, 24, 12, 68,\n",
              "       49, 35, 29, 29, 37, 13, 59, 32, 53, 72, 20, 75,  0, 62, 74, 22, 47,\n",
              "       27,  7, 58, 48,  7, 37, 42, 20, 65, 28, 62, 58, 47, 45,  4, 49, 39,\n",
              "       19, 11, 13, 54, 37, 13, 74, 41, 74, 17, 37, 12, 34, 75,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEcZ-0GHdkA",
        "outputId": "45c68109-3d50-460e-a1bd-0a7638445dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\"u live it will be in your armswithout leaving mine.\\n\\nYours is the light by which my spirit's born: -\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"v(tN3jVSE6HQ0(4.IF\\n)cdrfIWs;&kiLRkr3t'!kgDZ ,[UNK]u'A1sZLFFN2jIdw9z[UNK]my;XD)iY)NS9pEmiXV&ZP802eN2yRy6N1Kz&\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nsWYLnFqJR3G"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqSWNQkeKIHo",
        "outputId": "a2941116-0c04-4398-d472-a4e292bea98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 76)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.3310246\n"
          ]
        }
      ],
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSK7_Cj_MLxU",
        "outputId": "9dc91ec0-4199-407a-bebb-f4c5891cdaf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.02215"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "tf.exp(mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5BkGx7MhMNG9"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BeYulcWQMQoW"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ljnVG5UyMZx6"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ff7ny0aMk1n",
        "outputId": "1f763be2-19b7-433c-99ac-658e0f2d597e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "165/165 [==============================] - 28s 137ms/step - loss: 1.3925\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 24s 135ms/step - loss: 1.3150\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 24s 136ms/step - loss: 1.2578\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 24s 135ms/step - loss: 1.2078\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 24s 135ms/step - loss: 1.1596\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 24s 135ms/step - loss: 1.1117\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 24s 136ms/step - loss: 1.0619\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 24s 136ms/step - loss: 1.0092\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 24s 136ms/step - loss: 0.9542\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 24s 136ms/step - loss: 0.8965\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8BieBYsUOdHD"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VZ9yXF8mOpwc"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nOLFQzPXOwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd81b86a-fe91-42ff-c6c2-1232ce54af51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time would ever make my mind up at you, and still see his souls the singular pleasure champing wings as they also believe: Denuer, there is a word surprises ang right. When all let stories, the taste of your soul lasts eye and feel here. A long time, times fragile, earning by one deserve brave. A woman becomes the things we did their minds in the sepanding of a girl will become negative 'dill and be loved by ladies, that is what it works.\n",
            "\n",
            "I'll be sigzon's story eternal such is an agreesboxt door.\n",
            "\n",
            "He looked so we're anl ordinary passionate - Dreaming, the kind of person with unrealized.\n",
            "\n",
            "If there crosses sy long enough, attracted ones and show, the door will be the gates to climb a thousand madic don for the purpose of just because her no oceancies normally face and neither hand it to him, then future never quite perfection.\n",
            "\n",
            "I never want to keep going. If it was not the way you think you have to do something, we don't, shinking. And who is borrowed. Maybe even foone,There are firmly wing \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.800899267196655\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant([\"Once upon a time\"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "pvOpXjP0n4QW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn_quotes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}