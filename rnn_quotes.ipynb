{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanlopezzzz/instagram-bot/blob/jorge_m/rnn_quotes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MUgSMijpDsRj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZI98DxBLn4P9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adb7163-073e-4cd3-cc81-6e7de7ae93f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZyKygnXn4P-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PkiSap1E0-p",
        "outputId": "7349e2e6-3300-41f6-dc7a-d01ffe8751e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of text: 4309536 characters\n"
          ]
        }
      ],
      "source": [
        "text = open('/content/gdrive/MyDrive/Text-Gen/quote.txt', 'r').read()\n",
        "print(f'length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKoGgQN6J2iI",
        "outputId": "b691b368-0da2-41fb-d525-1f695820a40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "You need a little bit of insanity to do great things.\n",
            "\n",
            "Honor your joy today, whilst it replenishes and strengthens you - in the company of your Soul.\n",
            "\n",
            "Give your Friends Roses while they are still alive\n",
            "\n",
            "Even if there are instances in which it can b\n"
          ]
        }
      ],
      "source": [
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ9RkvrSIg5r",
        "outputId": "749cc911-65e1-4aca-80f1-31f4f976f6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 unique characters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b61WVuVFLU76",
        "outputId": "8874b4bf-9131-4fc0-ed31-e0364124bc8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Before training, you need to convert the strings to a numerical representation.\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding = 'UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmqi1xBbMZpi",
        "outputId": "d01b881e-310d-41b0-95d3-9515e6bba25e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[51, 52, 53, 54, 55, 56, 57], [74, 75, 76]]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary = list(vocab), mask_token = None)\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYbmM67MzmD",
        "outputId": "64a30e9e-45dd-4491-8220-cf00887fd815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI0JFqyeXA5M",
        "outputId": "32dfa987-c183-420d-baaa-b6a680cf37b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars,axis = -1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7rYRbOBXZJJ2"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFX55N3cT7EJ",
        "outputId": "400994a8-693a-4d3a-c5f2-cceebccdd947"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVRiwA_oTZTD",
        "outputId": "07b5165a-181a-45db-e156-608e20c0f042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Y\n",
            "o\n",
            "u\n",
            " \n",
            "n\n",
            "e\n",
            "e\n",
            "d\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFQD2baaJBD",
        "outputId": "c5f088ad-0404-4cd9-d1f5-2f044dd689c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\n' b'\\n' b'Y' b'o' b'u' b' ' b'n' b'e' b'e' b'd' b' ' b'a' b' ' b'l'\n",
            " b'i' b't' b't' b'l' b'e' b' ' b'b' b'i' b't' b' ' b'o' b'f' b' ' b'i'\n",
            " b'n' b's' b'a' b'n' b'i' b't' b'y' b' ' b't' b'o' b' ' b'd' b'o' b' '\n",
            " b'g' b'r' b'e' b'a' b't' b' ' b't' b'h' b'i' b'n' b'g' b's' b'.' b'\\n'\n",
            " b'\\n' b'H' b'o' b'n' b'o' b'r' b' ' b'y' b'o' b'u' b'r' b' ' b'j' b'o'\n",
            " b'y' b' ' b't' b'o' b'd' b'a' b'y' b',' b' ' b'w' b'h' b'i' b'l' b's'\n",
            " b't' b' ' b'i' b't' b' ' b'r' b'e' b'p' b'l' b'e' b'n' b'i' b's' b'h'\n",
            " b'e' b's' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder = True)\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ETrGCTucmiD7"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEAeWsKzn-Og",
        "outputId": "960cc569-bca3-4498-ee67-2658bc99297b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['t', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "split_input_target(list('tensorflow'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9McbdhooIfq",
        "outputId": "1f002102-b8fc-4da9-d5f6-cb87e0e0f968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7AMxfQXotUd",
        "outputId": "5c12d830-e89b-4dbc-a3dd-a0e5105b3ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'\\n\\nYou need a little bit of insanity to do great things.\\n\\nHonor your joy today, whilst it replenishes'\n",
            "Target: b'\\nYou need a little bit of insanity to do great things.\\n\\nHonor your joy today, whilst it replenishes '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkOIG6-V7m53",
        "outputId": "461e4b54-2bfd-47b8-e812-928bd0d56ef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences, \n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
        "# it maintains a buffer in which it shuffles elements)\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_xgxHrtS-gsq"
      },
      "outputs": [],
      "source": [
        "#Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "#The embedding dimension\n",
        "embedding_dim = 256\n",
        "#Number of RNN Units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "reNmEh-I_Hc_"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "model = MyModel (\n",
        "        #be sure the vocabulary size matches the 'StringLookup' layers.\n",
        "        vocab_size = len(ids_from_chars.get_vocabulary()), embedding_dim = embedding_dim, rnn_units = rnn_units\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFwQjN9oF6d3",
        "outputId": "2b6706b1-ddc3-4915-edc2-8876c9f7a203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 77) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fyJvbXHMVb",
        "outputId": "bfb94707-e0ef-4e3f-f4a3-7a21fae325f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  19712     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  78925     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,036,941\n",
            "Trainable params: 4,036,941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKwwSTtRHQWs",
        "outputId": "bfb86933-7033-497b-e209-8b7affd3c053"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27, 63, 21, 74, 69, 21, 21,  6, 72, 15,  6, 61, 66, 38, 44, 71, 41,\n",
              "       41, 47,  6,  5, 21, 27, 52, 74, 70, 72,  4, 50, 45,  0, 21, 70, 52,\n",
              "        7, 17, 43,  0, 71, 76, 18, 12, 45, 17, 29, 30, 69, 20, 43, 58, 33,\n",
              "       52,  0,  9, 75, 13, 21, 69,  4, 66, 24, 23,  4, 43,  4, 31, 72, 23,\n",
              "       46, 52, 54, 27, 48, 65, 60, 70, 31, 16,  2, 71, 52, 57, 55, 30, 66,\n",
              "       20, 15, 45, 31,  2, 75, 62, 22, 10, 54, 32,  0, 76, 74, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEcZ-0GHdkA",
        "outputId": "89d2020e-e9ea-4351-e31f-440c2019c848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'e present is the vivid fringe of memory tinged with anticipation.\\n\\nConstitutional democracy, you see'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"Cm9xs99'v3'kpNTuQQW'&9Cbxtv$ZU[UNK]9tb(5S[UNK]uz60U5EFs8ShIb[UNK],y19s$p?;$S$Gv;VbdCXojtG4 ubgeFp83UG yl:-dH[UNK]zx6\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nsWYLnFqJR3G"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqSWNQkeKIHo",
        "outputId": "c299a224-c862-4e35-8554-ed5b1f7ef13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 77)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.3441744\n"
          ]
        }
      ],
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSK7_Cj_MLxU",
        "outputId": "10b88828-e893-4304-8036-dded36e9e9e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.02842"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tf.exp(mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5BkGx7MhMNG9"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BeYulcWQMQoW"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ljnVG5UyMZx6"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ff7ny0aMk1n",
        "outputId": "f6146f75-8c0b-462b-c023-550772976fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "666/666 [==============================] - 94s 128ms/step - loss: 1.9460\n",
            "Epoch 2/10\n",
            "666/666 [==============================] - 87s 128ms/step - loss: 1.3613\n",
            "Epoch 3/10\n",
            "666/666 [==============================] - 86s 127ms/step - loss: 1.2652\n",
            "Epoch 4/10\n",
            "666/666 [==============================] - 86s 127ms/step - loss: 1.2169\n",
            "Epoch 5/10\n",
            "666/666 [==============================] - 86s 126ms/step - loss: 1.1826\n",
            "Epoch 6/10\n",
            "666/666 [==============================] - 86s 126ms/step - loss: 1.1536\n",
            "Epoch 7/10\n",
            "666/666 [==============================] - 86s 127ms/step - loss: 1.1274\n",
            "Epoch 8/10\n",
            "666/666 [==============================] - 86s 127ms/step - loss: 1.1031\n",
            "Epoch 9/10\n",
            "666/666 [==============================] - 86s 127ms/step - loss: 1.0800\n",
            "Epoch 10/10\n",
            "666/666 [==============================] - 87s 128ms/step - loss: 1.0586\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8BieBYsUOdHD"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VZ9yXF8mOpwc"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nOLFQzPXOwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5199d9-48c1-40d5-f29d-101b1bbd3e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time enclan my heart.\n",
            "\n",
            "People dear to always be beautiful.burning a moment when you are not one of them past it.\n",
            "\n",
            "Blame the Sun.\n",
            "\n",
            "Too much listen to a thankful girl is to control the world.\n",
            "\n",
            "Programmers of a matter of cheapes never then.\n",
            "\n",
            "The great have a professionally rest of everlasting glorious action arraves later what 79 on Design must provide world comfortly & worship to be Jakes\n",
            "\n",
            "My kids not make offered a wife there,and until He picking deadlines of oneself\n",
            "\n",
            "People measured smile at your destination. People care about your nacklew tempesses.\n",
            "\n",
            "Seek me and now, even if nothing happens about our life.\n",
            "\n",
            "You must build an entive leader and a job the food.'\n",
            "she chose meetings and pastier.\n",
            "\n",
            "Fear is the art of control and life.\n",
            "\n",
            "When two piccess as important as the only two types of ANG had -but desire for success.\n",
            "\n",
            "My mom andones your ideas of yourself; touching the stars:you were since you find that more things person.\n",
            "\n",
            "It has a vision that I love stretched choice.\n",
            "\n",
            "...practicing is con \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.700767993927002\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant([\"Once upon a time\"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pvOpXjP0n4QW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnn_quotes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}